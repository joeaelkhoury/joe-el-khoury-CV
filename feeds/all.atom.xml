<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Joe El Khoury - Data Scientist &amp; MLOps Expert</title><link href="https://joeaelkhoury/Joe-el-khoury-CV.github.io/" rel="alternate"></link><link href="https://joeaelkhoury/Joe-el-khoury-CV.github.io/feeds/all.atom.xml" rel="self"></link><id>https://joeaelkhoury/Joe-el-khoury-CV.github.io/</id><updated>2024-07-12T00:00:00+02:00</updated><entry><title>Strategies for Team Success in LLM Application Development ðŸš€</title><link href="https://joeaelkhoury/Joe-el-khoury-CV.github.io/strategies-for-team-success-in-llm-application-development.html" rel="alternate"></link><published>2024-07-12T00:00:00+02:00</published><updated>2024-07-12T00:00:00+02:00</updated><author><name>Joe El Khoury</name></author><id>tag:joeaelkhoury,2024-07-12:/Joe-el-khoury-CV.github.io/strategies-for-team-success-in-llm-application-development.html</id><content type="html">&lt;p&gt;Below I will share some thoughts about team management challenges, ideas and solutions that can help LLM teams which can be faced by developers and managers in the field.&lt;/p&gt;
&lt;p&gt;[Content of your article here]&lt;/p&gt;</content><category term="Team Management"></category><category term="LLM"></category><category term="Team Management"></category><category term="AI Development"></category></entry><entry><title>Leveraging Large Language Models for Automated Code Migration and Repository-Level Tasks â€” Part I</title><link href="https://joeaelkhoury/Joe-el-khoury-CV.github.io/leveraging-large-language-models-for-automated-code-migration-and-repository-level-tasks-part-i.html" rel="alternate"></link><published>2024-07-11T00:00:00+02:00</published><updated>2024-07-11T00:00:00+02:00</updated><author><name>Joe El Khoury</name></author><id>tag:joeaelkhoury,2024-07-11:/Joe-el-khoury-CV.github.io/leveraging-large-language-models-for-automated-code-migration-and-repository-level-tasks-part-i.html</id><content type="html">&lt;p&gt;How LLMs Are Transforming Software Engineering and Tackling Complex Repository-Level Tasks.&lt;/p&gt;
&lt;p&gt;[Content of your article here]&lt;/p&gt;</content><category term="Software Development"></category><category term="LLM"></category><category term="Software Development"></category><category term="AI"></category><category term="Business"></category></entry><entry><title>Neural Ordinary Differential Equations and Free-form Continuous Dynamics: A Revolution in Deep Learning</title><link href="https://joeaelkhoury/Joe-el-khoury-CV.github.io/neural-ordinary-differential-equations-and-free-form-continuous-dynamics-a-revolution-in-deep-learning.html" rel="alternate"></link><published>2024-07-08T00:00:00+02:00</published><updated>2024-07-08T00:00:00+02:00</updated><author><name>Joe El Khoury</name></author><id>tag:joeaelkhoury,2024-07-08:/Joe-el-khoury-CV.github.io/neural-ordinary-differential-equations-and-free-form-continuous-dynamics-a-revolution-in-deep-learning.html</id><content type="html">&lt;p&gt;Introduction:
[Your introduction to Neural ODEs and their impact on deep learning]&lt;/p&gt;
&lt;p&gt;[Content of your article here]&lt;/p&gt;</content><category term="Deep Learning"></category><category term="Neural ODEs"></category><category term="Continuous Dynamics"></category></entry><entry><title>TEXTGRAD vs DSPY : Revolutionizing AI System Optimization through Automatic Text-Based Prompting</title><link href="https://joeaelkhoury/Joe-el-khoury-CV.github.io/textgrad-vs-dspy-revolutionizing-ai-system-optimization-through-automatic-text-based-prompting.html" rel="alternate"></link><published>2024-06-17T00:00:00+02:00</published><updated>2024-06-17T00:00:00+02:00</updated><author><name>Joe El Khoury</name></author><id>tag:joeaelkhoury,2024-06-17:/Joe-el-khoury-CV.github.io/textgrad-vs-dspy-revolutionizing-ai-system-optimization-through-automatic-text-based-prompting.html</id><content type="html">&lt;p&gt;In the rapidly evolving landscape of AI, there is a paradigm shift towards building compound systems involving multiple sophisticated components.&lt;/p&gt;
&lt;p&gt;[Content of your article here]&lt;/p&gt;</content><category term="AI"></category><category term="TEXTGRAD"></category><category term="DSPY"></category><category term="AI Optimization"></category></entry><entry><title>Brain-Inspired Technologies that are Advancing AI</title><link href="https://joeaelkhoury/Joe-el-khoury-CV.github.io/brain-inspired-technologies-that-are-advancing-ai.html" rel="alternate"></link><published>2024-06-13T00:00:00+02:00</published><updated>2024-06-13T00:00:00+02:00</updated><author><name>Joe El Khoury</name></author><id>tag:joeaelkhoury,2024-06-13:/Joe-el-khoury-CV.github.io/brain-inspired-technologies-that-are-advancing-ai.html</id><content type="html">&lt;p&gt;[Introduction to brain-inspired technologies in AI]&lt;/p&gt;
&lt;p&gt;[Content of your article here]&lt;/p&gt;</content><category term="AI"></category><category term="Neuroscience"></category><category term="AI Advancements"></category></entry><entry><title>Unlocking the Semantics of CAD Programs: A Novel Approach to Automated Commenting</title><link href="https://joeaelkhoury/Joe-el-khoury-CV.github.io/unlocking-the-semantics-of-cad-programs-a-novel-approach-to-automated-commenting.html" rel="alternate"></link><published>2024-06-07T00:00:00+02:00</published><updated>2024-06-07T00:00:00+02:00</updated><author><name>Joe El Khoury</name></author><id>tag:joeaelkhoury,2024-06-07:/Joe-el-khoury-CV.github.io/unlocking-the-semantics-of-cad-programs-a-novel-approach-to-automated-commenting.html</id><content type="html">&lt;p&gt;[Introduction to the challenge of understanding CAD program semantics]&lt;/p&gt;
&lt;p&gt;[Content of your article here]&lt;/p&gt;</content><category term="CAD"></category><category term="CAD"></category><category term="Automated Commenting"></category><category term="AI"></category></entry><entry><title>Insights into Consistency Large Language Models (CLLMs)</title><link href="https://joeaelkhoury/Joe-el-khoury-CV.github.io/insights-into-consistency-large-language-models-cllms.html" rel="alternate"></link><published>2024-05-12T00:00:00+02:00</published><updated>2024-05-12T00:00:00+02:00</updated><author><name>Joe El Khoury</name></author><id>tag:joeaelkhoury,2024-05-12:/Joe-el-khoury-CV.github.io/insights-into-consistency-large-language-models-cllms.html</id><content type="html">&lt;p&gt;In the rapidly evolving field of artificial intelligence, the development of large language models (LLMs) like GPT (Generative Pre-trained Transformer) has revolutionized natural language processing.&lt;/p&gt;
&lt;p&gt;[Content of your article here]&lt;/p&gt;</content><category term="AI"></category><category term="CLLMs"></category><category term="Language Models"></category></entry><entry><title>JEPA is the Future of Video Understanding</title><link href="https://joeaelkhoury/Joe-el-khoury-CV.github.io/jepa-is-the-future-of-video-understanding.html" rel="alternate"></link><published>2024-04-19T00:00:00+02:00</published><updated>2024-04-19T00:00:00+02:00</updated><author><name>Joe El Khoury</name></author><id>tag:joeaelkhoury,2024-04-19:/Joe-el-khoury-CV.github.io/jepa-is-the-future-of-video-understanding.html</id><content type="html">&lt;p&gt;Yann LeCun, a prominent figure in artificial intelligence, believes that the future of AI lies not in generative models, but in predictive ones.&lt;/p&gt;
&lt;p&gt;[Content of your article here]&lt;/p&gt;</content><category term="AI"></category><category term="JEPA"></category><category term="Video Understanding"></category></entry><entry><title>Why Mamba was rejected?</title><link href="https://joeaelkhoury/Joe-el-khoury-CV.github.io/why-mamba-was-rejected.html" rel="alternate"></link><published>2024-02-28T00:00:00+01:00</published><updated>2024-02-28T00:00:00+01:00</updated><author><name>Joe El Khoury</name></author><id>tag:joeaelkhoury,2024-02-28:/Joe-el-khoury-CV.github.io/why-mamba-was-rejected.html</id><content type="html">&lt;p&gt;Recently, the International Conference on Learning Representations (ICLR) announced its final decisions for the 2024 conference, drawing attention to the rejection of the Mamba model.&lt;/p&gt;
&lt;p&gt;[Content of your article here]&lt;/p&gt;</content><category term="AI"></category><category term="Mamba"></category><category term="ICLR"></category><category term="Conference"></category></entry><entry><title>What is Mamba?</title><link href="https://joeaelkhoury/Joe-el-khoury-CV.github.io/what-is-mamba.html" rel="alternate"></link><published>2023-12-11T00:00:00+01:00</published><updated>2023-12-11T00:00:00+01:00</updated><author><name>Joe El Khoury</name></author><id>tag:joeaelkhoury,2023-12-11:/Joe-el-khoury-CV.github.io/what-is-mamba.html</id><content type="html">&lt;p&gt;The following article will just introduce lightly and simply the new Mamba model without diving technically.&lt;/p&gt;
&lt;p&gt;[Content of your Medium article here]&lt;/p&gt;</content><category term="Blog"></category></entry></feed>